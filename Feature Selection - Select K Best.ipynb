{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1254b87-0bb2-4792-9359-5b865d075072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff858c3-c276-4055-85d7-43ea4ee0e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectkbest(indep_X,dep_Y,n):\n",
    "        test = SelectKBest(score_func=chi2, k=n)\n",
    "        fit1= test.fit(indep_X,dep_Y)\n",
    "        selectk_features = fit1.transform(indep_X)\n",
    "        return selectk_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9979f-3362-44d2-a126-6cb496f091bc",
   "metadata": {},
   "source": [
    "Explanation of the Code\n",
    "The code defines a Python function selectkbest that uses feature selection to select the top n features from a dataset based on their statistical relevance to the target variable (dep_Y). Here's a detailed breakdown of the function:\n",
    "\n",
    "def selectkbest(indep_X, dep_Y, n):\n",
    "\n",
    "indep_X: Input features (independent variables).\n",
    "dep_Y: Target variable (dependent variable).\n",
    "n: The number of top features to select.\n",
    "\n",
    "1) Initialize SelectKBest:\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=n)\n",
    "\n",
    "SelectKBest: A feature selection method from sklearn.feature_selection. It scores each feature individually for relevance to the target.\n",
    "score_func=chi2: Uses the Chi-Square test to measure the dependence between features and the target. Suitable for categorical or non-negative data.\n",
    "k=n: Specifies how many of the top features to select.\n",
    "\n",
    "2) Fit the Model:\n",
    "\n",
    "fit1 = test.fit(indep_X, dep_Y)\n",
    "\n",
    "3) Transform the Data:\n",
    "\n",
    "   selectk_features = fit1.transform(indep_X)\n",
    "   \n",
    "fit1.transform(): Reduces the dataset (indep_X) to only the top n selected features based on the scores computed in the previous step.\n",
    "\n",
    "4) Return Selected Features:\n",
    "\n",
    " return selectk_features\n",
    " \n",
    "Outputs the reduced dataset containing only the selected top n features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c420080-522a-4047-a564-163df602b173",
   "metadata": {},
   "source": [
    "# Function: `selectkbest`\n",
    "\n",
    "This function performs feature selection using the Chi-Square test to identify and retain the most relevant features from the dataset.\n",
    "\n",
    "## Parameters:\n",
    "- `indep_X`: DataFrame or array of independent variables (features).\n",
    "- `dep_Y`: Series or array of the target variable.\n",
    "- `n`: Integer specifying the number of top features to select.\n",
    "\n",
    "## Function Logic:\n",
    "1. **Initialize SelectKBest**:\n",
    "   - Uses `SelectKBest` from `sklearn.feature_selection`.\n",
    "   - The scoring function is `chi2`, which calculates the Chi-Square scores of the features relative to the target variable.\n",
    "   - `k=n` specifies how many top features to retain.\n",
    "\n",
    "2. **Fit the Feature Selector**:\n",
    "   - `fit1 = test.fit(indep_X, dep_Y)` computes Chi-Square scores for all features.\n",
    "\n",
    "3. **Transform the Dataset**:\n",
    "   - `selectk_features = fit1.transform(indep_X)` selects the top `n` features from the original dataset.\n",
    "\n",
    "4. **Return Selected Features**:\n",
    "   - The function returns the dataset reduced to the `n` most relevant features.\n",
    "\n",
    "## Example Usage:\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Assuming indep_X and dep_Y are already defined\n",
    "selected_features = selectkbest(indep_X, dep_Y, 5)  # Select top 5 features\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563751e-9da3-4fd3-a4e2-23867ac949dd",
   "metadata": {},
   "source": [
    "This function is commonly used in **preprocessing pipelines** to reduce the dimensionality of datasets and improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34ae346-bcb6-49ec-8f43-f9dde6461068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f94a97-6b14-4de9-9c8e-0b8d72d19b61",
   "metadata": {},
   "source": [
    "### Explanation of the `split_scalar` Function\n",
    "\n",
    "The `split_scalar` function is designed to perform two primary tasks: splitting the dataset into training and testing sets, and standardizing the feature data for better model performance.\n",
    "\n",
    "#### Function Components:\n",
    "\n",
    "1. **Splitting the Dataset:**\n",
    "   ```python\n",
    "   X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9a42c-8a57-4495-bbad-2ce54d1358f7",
   "metadata": {},
   "source": [
    "This step divides the dataset into training and testing subsets.\n",
    "- **indep_X (independent variables or features)** and **dep_Y (dependent variable or target)** are split.\n",
    "- **test_size=0.25** means 25% of the data is allocated to the test set, and the remaining 75% is used for training.\n",
    "- **random_state=0** ensures the split is reproducible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0d2a9-eea3-4fba-aa7f-044445d77b79",
   "metadata": {},
   "source": [
    "#### Step 2: Standardizing the Data:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "- **Standardization** ensures that the data is scaled to have a mean of 0 and a standard deviation of 1.\n",
    "- **StandardScaler** is used for this purpose.\n",
    "- **fit_transform** is applied to the training data to compute the scaling parameters (mean and variance) and then scale the training data.\n",
    "- **transform** applies the same scaling parameters to the test data to ensure consistency.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c0e74-3b93-426d-90ae-43c5cd509539",
   "metadata": {},
   "source": [
    "### Step 3: Return Values\n",
    "\n",
    "```python\n",
    "return X_train, X_test, y_train, y_test\n",
    "\n",
    "**Outputs:**\n",
    "- **X_train:** Scaled training features.\n",
    "- **X_test:** Scaled testing features.\n",
    "- **y_train:** Training labels.\n",
    "- **y_test:** Testing labels.\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "**Data Splitting:**\n",
    "- Provides separate datasets for training and testing, enabling evaluation of model performance on unseen data.\n",
    "\n",
    "**Feature Scaling:**\n",
    "- Improves the performance of models sensitive to feature magnitudes, such as logistic regression, SVM, and neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac5b4e-0dbf-41ce-8ae2-866c7458a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f87a67-b249-4f74-a4f6-cf66df21e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd729b-456f-48c2-bf8e-5f27123fdb56",
   "metadata": {},
   "source": [
    "### `cm_prediction` Function Details\n",
    "\n",
    "The `cm_prediction` function evaluates a trained classifier by making predictions on the test data and generating metrics such as a confusion matrix, accuracy score, and classification report.\n",
    "\n",
    "---\n",
    "\n",
    "#### Function Code:\n",
    "```python\n",
    "def cm_prediction(classifier, X_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Calculating Accuracy and Generating Classification Report\n",
    "    from sklearn.metrics import accuracy_score \n",
    "    from sklearn.metrics import classification_report \n",
    "\n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return classifier, Accuracy, report, X_test, y_test, cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66fef4-bd2f-4f4a-a3e0-bdc0532a590c",
   "metadata": {},
   "source": [
    "### Step 1: Make Predictions\n",
    "\n",
    "```python\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "**Input:**\n",
    "- **classifier:** A trained machine learning model.\n",
    "- **X_test:** Test feature set.\n",
    "\n",
    "**Process:**\n",
    "- The classifier makes predictions (`y_pred`) for the test features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55d274-1725-4f44-8bf6-bc54f9d53841",
   "metadata": {},
   "source": [
    "### Step 2: Compute the Confusion Matrix\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mtx)\n",
    "\n",
    "**Confusion Matrix:**\n",
    "- A table that describes the performance of the classification model by comparing the actual and predicted labels.\n",
    "\n",
    "**Input:**\n",
    "- **y_test:** True labels for the test set.\n",
    "- **y_pred:** Predicted labels.\n",
    "\n",
    "**Output:**\n",
    "- **cm:** Confusion matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb197f2d-6694-4f21-b8cd-68033d4e8707",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Accuracy\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "**Accuracy Score:** Measures the percentage of correct predictions.\n",
    "\n",
    "**Input:**\n",
    "- **y_test:** True labels.\n",
    "- **y_pred:** Predicted labels.\n",
    "\n",
    "**Output:**\n",
    "- **Accuracy:** A float representing the model's accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deda297-40f1-4900-93bc-180c3504dc9a",
   "metadata": {},
   "source": [
    "### Step 4: Generate Classification Report\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "**Classification Report:** Summarizes precision, recall, F1-score, and support for each class.\n",
    "\n",
    "**Output:**\n",
    "- **report:** A string containing detailed classification metrics.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef2c0b-0b82-4eaa-a099-83d0f565938a",
   "metadata": {},
   "source": [
    "### Step 5: Return Results\n",
    "\n",
    "\n",
    "```python\n",
    "return classifier, Accuracy, report, X_test, y_test, cm\n",
    "\n",
    "**Outputs:**\n",
    "- **classifier:** The input model.\n",
    "- **Accuracy:** Model accuracy on the test set.\n",
    "- **report:** Detailed classification metrics.\n",
    "- **X_test:** Test features (for reference).\n",
    "- **y_test:** True test labels (for reference).\n",
    "- **cm:** Confusion matrix.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630c53f-9100-462a-9fee-860271471d0d",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "\n",
    "**Evaluation:**\n",
    "- Provides a comprehensive evaluation of the model's performance.\n",
    "\n",
    "**Metrics:**\n",
    "- Confusion matrix for analyzing correct and incorrect predictions.\n",
    "- Accuracy score for an overall performance snapshot.\n",
    "- Classification report for class-specific metrics like precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946076b-e84d-4ea9-8733-edf3c5e9e12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05dade60-4396-48f6-a0b5-3037a5135ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ceaa5e-1a66-48dd-9c33-84f1fe9a5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49ea726-6d8d-419f-9b67-c8e7b8a2b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09389fac-d58b-4b35-9665-1e1b8627b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c445e9-b39a-4a4b-bd52-24e5f96ab6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f252b34-e512-48c1-b736-7c244f88153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9659becb-8d59-407a-a275-63e54868487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d560084-15c4-4d5f-b053-b13ab6f91788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad105e1-d98e-4ce9-8730-b3130c461723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectk_Classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    dataframe=pd.DataFrame(index=['ChiSquare'],columns=['Logistic','SVMl','SVMnl','KNN','Navie','Decision','Random'])\n",
    "    for number,idex in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic'][idex]=acclog[number]       \n",
    "        dataframe['SVMl'][idex]=accsvml[number]\n",
    "        dataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        dataframe['KNN'][idex]=accknn[number]\n",
    "        dataframe['Navie'][idex]=accnav[number]\n",
    "        dataframe['Decision'][idex]=accdes[number]\n",
    "        dataframe['Random'][idex]=accrf[number]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec832575-5b05-45ee-807f-32d41fd6dc6e",
   "metadata": {},
   "source": [
    "### `selectk_Classification` Function Details\n",
    "\n",
    "The `selectk_Classification` function organizes classification accuracy scores for different models into a structured DataFrame for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### Function Code:\n",
    "```python\n",
    "def selectk_Classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf): \n",
    "    \n",
    "    dataframe = pd.DataFrame(index=['ChiSquare'], columns=['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Navie', 'Decision', 'Random'])\n",
    "    for number, idex in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic'][idex] = acclog[number]       \n",
    "        dataframe['SVMl'][idex] = accsvml[number]\n",
    "        dataframe['SVMnl'][idex] = accsvmnl[number]\n",
    "        dataframe['KNN'][idex] = accknn[number]\n",
    "        dataframe['Navie'][idex] = accnav[number]\n",
    "        dataframe['Decision'][idex] = accdes[number]\n",
    "        dataframe['Random'][idex] = accrf[number]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec716aca-93b5-42fa-bec0-e6351e9eab5e",
   "metadata": {},
   "source": [
    "### Explanation: Purpose\n",
    "\n",
    "This function creates a **DataFrame** to organize classification accuracies of multiple machine learning models (e.g., Logistic Regression, SVM, KNN, etc.) for a specified feature selection method, such as **ChiSquare**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04679d94-295c-47bd-ba35-77176754c64a",
   "metadata": {},
   "source": [
    "###  Input Parameters\n",
    "\n",
    "The function takes accuracy scores for different classification models as input:\n",
    "- **acclog:** Accuracy of Logistic Regression.\n",
    "- **accsvml:** Accuracy of Linear SVM.\n",
    "- **accsvmnl:** Accuracy of Non-Linear SVM.\n",
    "- **accknn:** Accuracy of KNN.\n",
    "- **accnav:** Accuracy of Naive Bayes.\n",
    "- **accdes:** Accuracy of Decision Tree.\n",
    "- **accrf:** Accuracy of Random Forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d12a10-5e4e-4920-a273-e9084a23a473",
   "metadata": {},
   "source": [
    "### Steps in Function:\n",
    "\n",
    "**Step 1:** Create an Empty DataFrame\n",
    "\n",
    "```python\n",
    "dataframe = pd.DataFrame(index=['ChiSquare'], columns=['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Navie', 'Decision', 'Random'])\n",
    "\n",
    "**The index** represents the feature selection method (e.g., ChiSquare).\n",
    "**The columns** represent classification models (e.g., Logistic, SVM, KNN, etc.).\n",
    "**Initially**, the DataFrame is empty.\n",
    "\n",
    "                                                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf79b400-8dd7-4f80-b784-2d82c90792f1",
   "metadata": {},
   "source": [
    "### Step 2: Populate the DataFrame\n",
    "\n",
    "```python\n",
    "for number, idex in enumerate(dataframe.index):      \n",
    "    dataframe['Logistic'][idex] = acclog[number]       \n",
    "    dataframe['SVMl'][idex] = accsvml[number]\n",
    "    dataframe['SVMnl'][idex] = accsvmnl[number]\n",
    "    dataframe['KNN'][idex] = accknn[number]\n",
    "    dataframe['Navie'][idex] = accnav[number]\n",
    "    dataframe['Decision'][idex] = accdes[number]\n",
    "    dataframe['Random'][idex] = accrf[number]\n",
    "\n",
    "- Iterates through the index of the DataFrame.\n",
    "- Assigns the corresponding accuracy values for each classification model into their respective columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb28544-6a81-46b4-ba67-c368fdf20cbf",
   "metadata": {},
   "source": [
    "### Step 3: Return the DataFrame\n",
    "\n",
    "```python\n",
    "return dataframe\n",
    "\n",
    "**Returns:** \n",
    "- The filled DataFrame for further analysis or visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178f8e1-6510-443a-92c7-2559b8c45297",
   "metadata": {},
   "source": [
    "### Output:\n",
    "\n",
    "A **DataFrame** where:\n",
    "\n",
    "- **Rows** represent feature selection methods (e.g., ChiSquare).  \n",
    "- **Columns** represent classification models with their respective accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e595f42-945d-493c-a4ae-e0f76163ccd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2cfebe-1571-4289-aa8d-c69d9f7fac93",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m df2\u001b[38;5;241m=\u001b[39mdataset1\n\u001b[0;32m      5\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df2, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m indep_X\u001b[38;5;241m=\u001b[39m\u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification_yes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m dep_Y\u001b[38;5;241m=\u001b[39mdf2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_yes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "dataset1=pd.read_csv(\"prep.csv\",index_col=None)\n",
    "\n",
    "df2=dataset1\n",
    "\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X=df2.drop('classification_yes', 1)\n",
    "dep_Y=df2['classification_yes']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffd07b-1454-4c50-bf74-dce0f1b3237b",
   "metadata": {},
   "source": [
    "The error occurs because the `DataFrame.drop()` method in pandas no longer accepts `1` or `0` as positional arguments for the `axis` parameter in modern versions of pandas. Instead, you should explicitly specify `axis=1` for dropping columns or `axis=0` for dropping rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c970664-6396-48b5-b348-3ac2a72c4d22",
   "metadata": {},
   "source": [
    "Here's the corrected version of the above code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3054630-3cf6-4ada-b493-0b0cb248ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         bp   al   su         bgr         bu        sc         sod  \\\n",
      "0  2.0  76.459948  3.0  0.0  148.112676  57.482105  3.077356  137.528754   \n",
      "1  3.0  76.459948  2.0  0.0  148.112676  22.000000  0.700000  137.528754   \n",
      "2  4.0  76.459948  1.0  0.0   99.000000  23.000000  0.600000  138.000000   \n",
      "3  5.0  76.459948  1.0  0.0  148.112676  16.000000  0.700000  138.000000   \n",
      "4  5.0  50.000000  0.0  0.0  148.112676  25.000000  0.600000  137.528754   \n",
      "\n",
      "        pot       hrmo  ...  rbc_normal  pc_normal  pcc_present  ba_present  \\\n",
      "0  4.627244  12.518156  ...           1          0            0           0   \n",
      "1  4.627244  10.700000  ...           1          1            0           0   \n",
      "2  4.400000  12.000000  ...           1          1            0           0   \n",
      "3  3.200000   8.100000  ...           1          1            0           0   \n",
      "4  4.627244  11.800000  ...           1          1            0           0   \n",
      "\n",
      "   htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  \n",
      "0        0       0        0          1       1        0  \n",
      "1        0       0        0          1       0        0  \n",
      "2        0       0        0          1       0        0  \n",
      "3        0       0        0          1       0        1  \n",
      "4        0       0        0          1       0        0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: classification_yes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset1 = pd.read_csv(\"prep.csv\", index_col=None)\n",
    "\n",
    "# Create a copy of the dataset\n",
    "df2 = dataset1\n",
    "\n",
    "# Perform one-hot encoding with drop_first=True\n",
    "df2 = pd.get_dummies(df2, dtype = int,drop_first=True)\n",
    "\n",
    "# Separate independent variables (X) and dependent variable (Y)\n",
    "indep_X = df2.drop('classification_yes', axis=1)  # Specify axis=1 explicitly\n",
    "dep_Y = df2['classification_yes']\n",
    "\n",
    "# Check the results\n",
    "print(indep_X.head())\n",
    "print(dep_Y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8d279-31b7-45c3-8e11-3b2d76acf76f",
   "metadata": {},
   "source": [
    "### Explanation of Changes:\n",
    "- **axis=1:** Explicitly specifying `axis=1` tells pandas to drop a column. The earlier `1` was being interpreted as a positional argument, which caused the error.\n",
    "- **General Syntax Update:** Modern pandas versions require clearer argument handling to avoid ambiguity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "125d6610-1fa9-4a12-9793-f5aabc2eb7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...          0            0           0   \n",
       "1    137.528754  4.627244  10.700000  ...          1            0           0   \n",
       "2    138.000000  4.400000  12.000000  ...          1            0           0   \n",
       "3    138.000000  3.200000   8.100000  ...          1            0           0   \n",
       "4    137.528754  4.627244  11.800000  ...          1            0           0   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...          1            0           0   \n",
       "395  137.528754  4.627244   8.700000  ...          1            0           0   \n",
       "396  134.000000  2.700000   9.100000  ...          1            0           0   \n",
       "397  142.000000  5.500000   8.500000  ...          1            0           0   \n",
       "398  140.000000  5.000000  16.300000  ...          1            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0          0       0        0          1       1        0                   1  \n",
       "1          0       0        0          1       0        0                   1  \n",
       "2          0       0        0          1       0        0                   1  \n",
       "3          0       0        0          1       0        1                   1  \n",
       "4          0       0        0          1       0        0                   1  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394        0       0        0          1       0        0                   1  \n",
       "395        1       1        0          1       0        1                   1  \n",
       "396        1       1        0          0       0        0                   1  \n",
       "397        1       1        0          1       0        1                   1  \n",
       "398        0       0        0          1       0        0                   0  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0f0e8ad-ecb6-42d5-ad72-80ca0357ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest=selectkbest(indep_X,dep_Y,6)       \n",
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0385ebf8-c353-4e26-ae80-7b3bbae02ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00000000e+00, 1.48112676e+02, 5.74821053e+01, 3.07735602e+00,\n",
       "        3.88689024e+01, 8.40819113e+03],\n",
       "       [2.00000000e+00, 1.48112676e+02, 2.20000000e+01, 7.00000000e-01,\n",
       "        3.40000000e+01, 1.23000000e+04],\n",
       "       [1.00000000e+00, 9.90000000e+01, 2.30000000e+01, 6.00000000e-01,\n",
       "        3.40000000e+01, 8.40819113e+03],\n",
       "       ...,\n",
       "       [3.00000000e+00, 1.10000000e+02, 1.15000000e+02, 6.00000000e+00,\n",
       "        2.60000000e+01, 9.20000000e+03],\n",
       "       [0.00000000e+00, 2.07000000e+02, 8.00000000e+01, 6.80000000e+00,\n",
       "        3.88689024e+01, 8.40819113e+03],\n",
       "       [0.00000000e+00, 1.00000000e+02, 4.90000000e+01, 1.00000000e+00,\n",
       "        5.30000000e+01, 8.50000000e+03]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4099ea4-39f1-4faf-96e0-a58619828d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could see from the above Kbest gives the best 4:\n",
    "\n",
    "# Such as \"bgr\tbu\tsc\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "179e7b9d-721f-4dfb-b379-695ca321a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This below code (X_train, X_test, y_train, y_test=split_scalar(kbest,dep_Y)  ) is for entering the best k values, before creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70fee599-96b6-4ffd-9f5c-8b4fb48e82c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:5: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Logistic'][idex]=acclog[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['SVMnl'][idex]=accsvmnl[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['KNN'][idex]=accknn[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Navie'][idex]=accnav[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12100\\2634354880.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataframe['Random'][idex]=accrf[number]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=split_scalar(kbest,dep_Y)   \n",
    "    \n",
    "        \n",
    "classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "acclog.append(Accuracy)\n",
    "\n",
    "classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "accsvml.append(Accuracy)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "accsvmnl.append(Accuracy)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "accknn.append(Accuracy)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "accnav.append(Accuracy)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "accdes.append(Accuracy)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "accrf.append(Accuracy)\n",
    "    \n",
    "result=selectk_Classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce8af0a5-1415-4b87-96e7-4de56b8194ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChiSquare</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic  SVMl SVMnl   KNN Navie Decision Random\n",
       "ChiSquare     0.94  0.94  0.95  0.89  0.83     0.96   0.95"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is for the K value --> 5\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10133187-58c5-46e8-8d08-abe11c0648d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChiSquare</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic  SVMl SVMnl   KNN Navie Decision Random\n",
       "ChiSquare     0.85  0.82  0.83  0.86  0.79     0.89   0.89"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is for the K value --> 4\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d3adbb-add9-4bde-911d-1104453c433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChiSquare</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic  SVMl SVMnl   KNN Navie Decision Random\n",
       "ChiSquare     0.82  0.82  0.82  0.85   0.8     0.84   0.83"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is for the K value --> 3\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ab40a32-1d32-4eea-95de-948eb3309b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChiSquare</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic  SVMl SVMnl   KNN Navie Decision Random\n",
       "ChiSquare     0.95  0.96  0.96  0.93  0.89     0.97   0.97"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is for the K value --> 6\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257ee09-da95-4eeb-b035-b22a41390d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above results, we we decide that K=6 gives best result--> 97 for Decision and Random Forest.\n",
    "\n",
    "# Further, we can use mode and ensamble learning also to conclude the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d54f93-fcda-4abe-a2bd-3f74e3b59c71",
   "metadata": {},
   "source": [
    "# To Determine the Best Model Using Mode and Ensemble Techniques\n",
    "\n",
    "## Step 1: Analyze with Mode\n",
    "The **mode** refers to the most frequently occurring value or choice. In this context, the mode can identify the classification model that performs well most consistently across feature selection techniques.\n",
    "\n",
    "### Process:\n",
    "- Extract the accuracy scores for all models.\n",
    "- Identify the model(s) with the highest accuracy for each row (feature selection method).\n",
    "- Find the **mode** of the models with the highest accuracy.\n",
    "\n",
    "### For the Provided Output:\n",
    "\n",
    "| Logistic | SVMl  | SVMnl | KNN   | Navie | Decision | Random |\n",
    "|----------|-------|-------|-------|-------|----------|--------|\n",
    "| 0.95     | 0.96  | 0.96  | 0.93  | 0.89  | 0.97     | 0.97   |\n",
    "\n",
    "The **Decision** and **Random Forest** models have the highest accuracy (0.97), so they are likely candidates for the best models.\n",
    "\n",
    "### Result:\n",
    "The **mode** approach suggests **Decision Tree** and **Random Forest** as the best-performing models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743e837-283a-4f05-92de-966757b7b750",
   "metadata": {},
   "source": [
    "### Step 2: Apply Ensemble Techniques\n",
    "\n",
    "Ensemble techniques combine predictions from multiple models to achieve better overall performance. The two most common approaches are:\n",
    "\n",
    "**Voting Ensemble:**\n",
    "- Combine predictions of all models (e.g., Logistic Regression, SVM, etc.).\n",
    "- Use a majority vote or weighted vote based on accuracy scores.\n",
    "\n",
    "**Example:**\n",
    "- Logistic = Correct Prediction\n",
    "- SVMl = Correct Prediction\n",
    "- SVMnl = Incorrect Prediction\n",
    "- KNN = Correct Prediction\n",
    "- Navie = Incorrect Prediction\n",
    "- Decision = Correct Prediction\n",
    "- Random = Correct Prediction\n",
    "- With majority vote, the ensemble predicts the majority outcome.\n",
    "\n",
    "**Averaging Ensemble:**\n",
    "- Compute the average probability predicted by each model for each class.\n",
    "- Use the class with the highest averaged probability as the final prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "988954fc-7158-4fdb-adab-29715e39f4da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decision_tree_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example: Combine the top-performing models\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m VotingClassifier(\n\u001b[0;32m      5\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m----> 6\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdecision_tree_model\u001b[49m),\n\u001b[0;32m      7\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, random_forest_model)\n\u001b[0;32m      8\u001b[0m     ],\n\u001b[0;32m      9\u001b[0m     voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 'soft' uses predicted probabilities; 'hard' uses predicted labels\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train ensemble model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ensemble_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Example: Combine the top-performing models\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('decision', decision_tree_model),\n",
    "        ('random', random_forest_model)\n",
    "    ],\n",
    "    voting='soft'  # 'soft' uses predicted probabilities; 'hard' uses predicted labels\n",
    ")\n",
    "\n",
    "# Train ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy\n",
    "ensemble_accuracy = ensemble_model.score(X_test, y_test)\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a8f15-678c-4089-8bf8-08513f1a4af8",
   "metadata": {},
   "source": [
    "The error `NameError: name 'decision_tree_model' is not defined` indicates that the variable `decision_tree_model` is not defined in your code. This is because you need to define or train the `decision_tree_model` and `random_forest_model` before passing them to the `VotingClassifier`.\n",
    "\n",
    "### Hereâ€™s how you can resolve the issue:\n",
    "\n",
    "**Steps to Fix the Error:**\n",
    "1. **Define and Train the Models:**\n",
    "   - Make sure you have imported the required classifiers and trained the `decision_tree_model` and `random_forest_model` on the training data (`X_train`, `y_train`) before using them in the ensemble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9db7875b-61e4-433e-bebb-1981073c7c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Initialize individual models\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=0)\n",
    "random_forest_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Step 2: Train the models\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Create the VotingClassifier (Ensemble)\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('decision', decision_tree_model),\n",
    "        ('random', random_forest_model)\n",
    "    ],\n",
    "    voting='soft'  # Use 'soft' for predicted probabilities, 'hard' for predicted labels\n",
    ")\n",
    "\n",
    "# Step 4: Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the ensemble model\n",
    "ensemble_accuracy = ensemble_model.score(X_test, y_test)\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268b6ea-a475-40a8-99a7-8484853877d0",
   "metadata": {},
   "source": [
    "### The Result: Ensemble Model Accuracy: 0.97\n",
    "\n",
    "The result **`Ensemble Model Accuracy: 0.97`** indicates that the ensemble model achieved 97% accuracy on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Result:\n",
    "\n",
    "#### High Accuracy:\n",
    "- The ensemble model, combining predictions from both the `DecisionTreeClassifier` and the `RandomForestClassifier`, performed exceptionally well on the test set.\n",
    "- A 97% accuracy means that the ensemble model correctly predicted the labels for 97% of the test samples.\n",
    "\n",
    "#### Ensemble Benefits:\n",
    "- By combining the strengths of the `DecisionTreeClassifier` and `RandomForestClassifier`, the ensemble model reduces individual model biases and variances.\n",
    "- Using `voting='soft'` allows the model to leverage probabilities, making it more robust and likely leading to better performance than individual models.\n",
    "\n",
    "---\n",
    "\n",
    "### What Contributed to the High Accuracy:\n",
    "1. **Dataset Quality:** \n",
    "   - Features in the training and testing sets may be well-processed (e.g., scaled and balanced).\n",
    "2. **Feature Selection:**\n",
    "   - If the dataset underwent feature selection (like `SelectKBest`), it would have reduced noise and improved performance.\n",
    "3. **Random Forest's Strength:**\n",
    "   - The Random Forest classifier is inherently strong at generalizing well to unseen data.\n",
    "4. **Complementary Nature of Models:**\n",
    "   - The Decision Trees and Random Forest models complement each other, improving the overall performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps for Evaluation:\n",
    "1. **Confusion Matrix:**\n",
    "   - Check for detailed insights into classification performance, such as false positives and false negatives.\n",
    "2. **Classification Report:**\n",
    "   - Generate a report to understand precision, recall, and F1-score for individual classes.\n",
    "3. **Cross-Validation:**\n",
    "   - Validate the model using cross-validation to ensure the high accuracy is not due to overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bf13f-e78a-416f-8aeb-d78d08726fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
